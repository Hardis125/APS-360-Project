{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2012,"status":"ok","timestamp":1712448382507,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"hacYiYI3_VME","outputId":"78cbacb5-2e6d-4a9d-cf9a-87219cee54e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# mount our Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z03uTP1G_3B7"},"outputs":[],"source":["# Import any needed libraries\n","import numpy as np\n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.transforms as transforms\n","import os\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from PIL import UnidentifiedImageError"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EILSQWvg_LPf"},"outputs":[],"source":["# Reference from Tut_3b\n","# define training, validation, and testing data directories\n","data_path = '/content/drive/My Drive/APS360Project/split'\n","train_path = os.path.join(data_path, 'train/')\n","valid_path = os.path.join(data_path, 'val/')\n","test_path = os.path.join(data_path, 'test/')\n","\n","# load and transform data using ImageFolder\n","# resize all images to 224 x 224\n","data_transform = transforms.Compose([transforms.Resize((224,224)),\n","                                      transforms.ToTensor()])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DNp-l11y_YXj"},"outputs":[],"source":["import os\n","import shutil"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1712439985187,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"9CpnWtRXPiwM","outputId":"c3407309-a1d0-4d49-d286-46ac9852431c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nsource_folder = \"/content/drive/MyDrive/APS360Project/split/train/\"\\ntarget_folder_1 = \"/content/drive/MyDrive/APS360Project/split/train/11/\"\\ntarget_folder_0 = \"/content/drive/MyDrive/APS360Project/split/train/00/\"\\n\\nfor filename in os.listdir(source_folder):\\n    if \"class1\" in filename:\\n        shutil.copy(os.path.join(source_folder, filename), target_folder_1)\\n    elif \"class0\" in filename:\\n        shutil.copy(os.path.join(source_folder, filename), target_folder_0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["# prompt: give me code to put all img files in a source folder into 2 folders named \"1\" or \"0\" given file names contains '1' or '0'\n","\n","\n","\n","'''\n","source_folder = \"/content/drive/MyDrive/APS360Project/split/train/\"\n","target_folder_1 = \"/content/drive/MyDrive/APS360Project/split/train/11/\"\n","target_folder_0 = \"/content/drive/MyDrive/APS360Project/split/train/00/\"\n","\n","for filename in os.listdir(source_folder):\n","    if \"class1\" in filename:\n","        shutil.copy(os.path.join(source_folder, filename), target_folder_1)\n","    elif \"class0\" in filename:\n","        shutil.copy(os.path.join(source_folder, filename), target_folder_0)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1712439985188,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"l-p97pXVqbkX","outputId":"379f8572-8ede-4971-a94f-94fd8c486b18"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nsource_folder = \"/content/drive/MyDrive/APS360Project/split/test/\"\\ntarget_folder_1 = \"/content/drive/MyDrive/APS360Project/split/test/11/\"\\ntarget_folder_0 = \"/content/drive/MyDrive/APS360Project/split/test/00/\"\\n\\nfor filename in os.listdir(source_folder):\\n    if \"class1\" in filename:\\n        shutil.copy(os.path.join(source_folder, filename), target_folder_1)\\n    elif \"class0\" in filename:\\n        shutil.copy(os.path.join(source_folder, filename), target_folder_0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}],"source":["'''\n","source_folder = \"/content/drive/MyDrive/APS360Project/split/test/\"\n","target_folder_1 = \"/content/drive/MyDrive/APS360Project/split/test/11/\"\n","target_folder_0 = \"/content/drive/MyDrive/APS360Project/split/test/00/\"\n","\n","for filename in os.listdir(source_folder):\n","    if \"class1\" in filename:\n","        shutil.copy(os.path.join(source_folder, filename), target_folder_1)\n","    elif \"class0\" in filename:\n","        shutil.copy(os.path.join(source_folder, filename), target_folder_0)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1712439985188,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"p9UR57iDqrmV","outputId":"a0558535-001f-47e2-c927-b46e776951f4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nsource_folder = \"/content/drive/MyDrive/APS360Project/split/val/\"\\ntarget_folder_1 = \"/content/drive/MyDrive/APS360Project/split/val/11/\"\\ntarget_folder_0 = \"/content/drive/MyDrive/APS360Project/split/val/00/\"\\n\\nfor filename in os.listdir(source_folder):\\n    if \"class1\" in filename:\\n        shutil.copy(os.path.join(source_folder, filename), target_folder_1)\\n    elif \"class0\" in filename:\\n        shutil.copy(os.path.join(source_folder, filename), target_folder_0)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}],"source":["'''\n","source_folder = \"/content/drive/MyDrive/APS360Project/split/val/\"\n","target_folder_1 = \"/content/drive/MyDrive/APS360Project/split/val/11/\"\n","target_folder_0 = \"/content/drive/MyDrive/APS360Project/split/val/00/\"\n","\n","for filename in os.listdir(source_folder):\n","    if \"class1\" in filename:\n","        shutil.copy(os.path.join(source_folder, filename), target_folder_1)\n","    elif \"class0\" in filename:\n","        shutil.copy(os.path.join(source_folder, filename), target_folder_0)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1712448145998,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"cIGPsOwaro1B","outputId":"ef0fe829-1a6d-412c-cb8f-696b06707d0f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Create data loaders for each set\\ntrain_loader = DataLoader(train_set, batch_size=2, shuffle=True)\\nval_loader = DataLoader(val_set, batch_size=2, shuffle=True)\\ntest_loader = DataLoader(test_set, batch_size=2, shuffle=True)\\n# define dataloader parameters\\n# choose a small size, ensuring the model can fit within the memory constraints\\nbatch_size  = 20\\n# positive num_workers can speed up the data-loading process\\n# the datasets in lab3 is large, so set num_workers=2 to help accelerate process\\nnum_workers = 2\\n\\n# prepare data loaders\\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\\n                                         num_workers=num_workers, shuffle=True)\\nval_loader = torch.utils.data.DataLoader(valid_data,batch_size=batch_size,\\n                                        num_workers=num_workers, shuffle=True)\\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\\n                                         num_workers=num_workers, shuffle=True)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["\n","\n"," # Skip this batch and move to the next\n","'''\n","# Further split the training set into training and validation sets\n","train_set, val_set = train_test_split(train_set, test_size=0.2, random_state=42)\n","'''\n","'''\n","# Create data loaders for each set\n","train_loader = DataLoader(train_set, batch_size=2, shuffle=True)\n","val_loader = DataLoader(val_set, batch_size=2, shuffle=True)\n","test_loader = DataLoader(test_set, batch_size=2, shuffle=True)\n","# define dataloader parameters\n","# choose a small size, ensuring the model can fit within the memory constraints\n","batch_size  = 20\n","# positive num_workers can speed up the data-loading process\n","# the datasets in lab3 is large, so set num_workers=2 to help accelerate process\n","num_workers = 2\n","\n","# prepare data loaders\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n","                                          num_workers=num_workers, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(valid_data,batch_size=batch_size,\n","                                         num_workers=num_workers, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n","                                          num_workers=num_workers, shuffle=True)\n","'''\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tFEZZWSCUId9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"executionInfo":{"elapsed":5,"status":"error","timestamp":1712439993754,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"NnDrcKAgxYn2","outputId":"b3b4891f-ad1b-4581-f971-6d2a250c8595"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"unterminated string literal (detected at line 24) (<ipython-input-16-5be34d0c5d21>, line 24)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-5be34d0c5d21>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    ''''\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 24)\n"]}],"source":["'''\n","class LabSmallCNN(nn.Module):\n","    def __init__(self):\n","        super(LabSmallCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1)\n","        self.relu = nn.ReLU()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        self.conv2 = nn.Conv2d(4, 5, kernel_size=3, stride=1, padding=1)\n","        self.fc1 = nn.Linear(5 * 56 * 56, 128)\n","        self.fc2 = nn.Linear(128, 2)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","        x = x.view(-1, 5 * 56 * 56)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","''''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01Ce4LqSzjwm","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1712440287677,"user_tz":240,"elapsed":258,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"}},"outputId":"f889f5f9-548b-482f-d138-d51bffd0d129"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ndef train(model, dataloader, batch_size=64, num_epochs=1):\\n    train_loader = dataloader\\n    criterion = nn.CrossEntropyLoss()\\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\\n\\n    iters, losses, train_acc, val_acc = [], [], [], []\\n\\n    # training\\n    n = 0 # the number of iterations\\n    for epoch in range(num_epochs):\\n        for imgs, labels in iter(train_loader):\\n\\n            out = model(imgs)             # forward pass\\n\\n            loss = criterion(out, labels) # compute the total loss\\n            loss.backward()               # backward pass (compute parameter updates)\\n            optimizer.step()              # make the updates for each parameter\\n            optimizer.zero_grad()         # a clean up step for PyTorch\\n\\n            # save the current training information\\n            iters.append(n)\\n            losses.append(float(loss)/batch_size)             # compute *average* loss\\n            train_acc.append(get_accuracy(model, train_loader)) # compute training accuracy\\n            val_acc.append(get_accuracy(model, train_loader))  # compute validation accuracy\\n            n += 1\\n\\n    # plotting\\n    plt.title(\"Training Curve\")\\n    plt.plot(iters, losses, label=\"Train\")\\n    plt.xlabel(\"Iterations\")\\n    plt.ylabel(\"Loss\")\\n    plt.show()\\n\\n    plt.title(\"Training Curve\")\\n    plt.plot(iters, train_acc, label=\"Train\")\\n    plt.plot(iters, val_acc, label=\"Validation\")\\n    plt.xlabel(\"Iterations\")\\n    plt.ylabel(\"Training Accuracy\")\\n    plt.legend(loc=\\'best\\')\\n    plt.show()\\n\\n    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\\n    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\\n    '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}],"source":["'''\n","def train(model, dataloader, batch_size=64, num_epochs=1):\n","    train_loader = dataloader\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","    iters, losses, train_acc, val_acc = [], [], [], []\n","\n","    # training\n","    n = 0 # the number of iterations\n","    for epoch in range(num_epochs):\n","        for imgs, labels in iter(train_loader):\n","\n","            out = model(imgs)             # forward pass\n","\n","            loss = criterion(out, labels) # compute the total loss\n","            loss.backward()               # backward pass (compute parameter updates)\n","            optimizer.step()              # make the updates for each parameter\n","            optimizer.zero_grad()         # a clean up step for PyTorch\n","\n","            # save the current training information\n","            iters.append(n)\n","            losses.append(float(loss)/batch_size)             # compute *average* loss\n","            train_acc.append(get_accuracy(model, train_loader)) # compute training accuracy\n","            val_acc.append(get_accuracy(model, train_loader))  # compute validation accuracy\n","            n += 1\n","\n","    # plotting\n","    plt.title(\"Training Curve\")\n","    plt.plot(iters, losses, label=\"Train\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    plt.title(\"Training Curve\")\n","    plt.plot(iters, train_acc, label=\"Train\")\n","    plt.plot(iters, val_acc, label=\"Validation\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Training Accuracy\")\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n","    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n","    '''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4xa0Pj-xbBe"},"outputs":[],"source":["'''\n","# pr'ompt: get accuracy for a binary classification CNN model\n","use_cuda = True\n","def get_accuracy(model, data_loader):\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in data_loader:\n","            if use_cuda and torch.cuda.is_available():\n","              images = images.cuda()\n","              labels = labels.cuda()\n","              outputs = model(images)\n","            else:\n","              outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return 100 * correct / total\n","    '''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IRA5LSZA0ihk"},"outputs":[],"source":["'''\n","def get_accuracy(model, data_loader):\n","    correct = 0\n","    total = 0\n","\n","    for imgs, labels in data_loader:\n","\n","        #############################################\n","        #To Enable GPU Usage\n","        if use_cuda and torch.cuda.is_available():\n","          imgs = imgs.cuda()\n","          labels = labels.cuda()\n","        #############################################\n","\n","        output = model(imgs)\n","\n","        #select index with maximum prediction score\n","        pred = output.max(1, keepdim=True)[1]\n","        correct += pred.eq(labels.view_as(pred)).sum().item()\n","        total += imgs.shape[0]\n","    return correct / total\n","    '''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B83VfSoaxd4u"},"outputs":[],"source":["def get_accuracy(model, data_loader, threshold=0.5):\n","    correct = 0\n","    total = 0\n","\n","    for imgs, labels in data_loader:\n","        #############################################\n","        # To Enable GPU Usage\n","        if use_cuda and torch.cuda.is_available():\n","            imgs = imgs.cuda()\n","            labels = labels.cuda()\n","        #############################################\n","\n","        output = model(imgs)\n","\n","        # Assuming output is a probability of the positive class\n","        # Convert probabilities to binary predictions based on a threshold\n","        pred = (output > threshold).float()  # Assuming output is between 0 and 1\n","\n","        correct += pred.eq(labels.view_as(pred)).sum().item()\n","        total += imgs.shape[0]\n","\n","    return correct / total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9AAU-YlIxgwm","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1712440311747,"user_tz":240,"elapsed":4,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"}},"outputId":"d075d1c4-787e-4856-a7d4-1a7633510cdc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nprint(\"CNN\")\\nmodel = LabSmallCNN()\\nprint(model)\\ntrain(model, train_loader, num_epochs=10)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}],"source":["'''\n","print(\"CNN\")\n","model = LabSmallCNN()\n","print(model)\n","train(model, train_loader, num_epochs=10)\n","'''"]},{"cell_type":"markdown","metadata":{"id":"_KKE5sQBEdL1"},"source":["#**SEE LAB3 CODES**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZ-mpEqnzP43"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Function to display images\n","def imshow(img):\n","    img = img / 2 + 0.5  # unnormalize\n","    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1712457329893,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"zEzUezUoET-r","outputId":"02d12147-9525-4186-91a2-101aab48787b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Convolutional Neural Network Architecture Done\n"]}],"source":["# Reference from Tut_3b\n","'''\n","# define training, validation, and testing data directories\n","data_path = '/content/drive/My Drive/APS360/Lab3datasets_split'\n","train_path = os.path.join(data_path, 'train/')\n","valid_path = os.path.join(data_path, 'val/')\n","test_path = os.path.join(data_path, 'test/')\n","\n","# classes are folders in each directory with the original file names\n","classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n","\n","# load and transform data using ImageFolder\n","# resize all images to 224 x 224\n","data_transform = transforms.Compose([transforms.Resize((224,224)),\n","                                      transforms.ToTensor()])\n","\n","train_data = datasets.ImageFolder(root=train_path, transform=data_transform)\n","valid_data = datasets.ImageFolder(root=valid_path, transform=data_transform)\n","test_data = datasets.ImageFolder(root=test_path, transform=data_transform)\n","\n","\n","# define dataloader parameters\n","# choose a small size, ensuring the model can fit within the memory constraints\n","batch_size  = 20\n","# positive num_workers can speed up the data-loading process\n","# the datasets in lab3 is large, so set num_workers=2 to help accelerate process\n","num_workers = 2\n","\n","# prepare data loaders\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n","                                          num_workers=num_workers, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(valid_data,batch_size=batch_size,\n","                                         num_workers=num_workers, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n","                                          num_workers=num_workers, shuffle=True)\n","\n","# Visualize some sample data\n","# obtain one batch of training images\n","dataiter = iter(train_loader)\n","images, labels = next(dataiter)\n","images = images.numpy() # convert images to numpy for display\n","\n","\n","# plot the images in the batch, along with the corresponding labels\n","# show 3 rows with 5 columns, 3*5=15 images in total\n","fig = plt.figure(figsize=(20, 5))\n","for idx in np.arange(15):\n","    ax = fig.add_subplot(3, int(15/3), idx+1, xticks=[], yticks=[])\n","    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n","    ax.set_title(classes[labels[idx]])\n","\n","# print data stats about numbers of train, val, and test images\n","print('Num training images: ', len(train_data))\n","print('Num validation images: ', len(valid_data))\n","print('Num testing images: ', len(test_data))\n","\n","\n","\n","'''\n","\n","# Reference from Lab2\n","# Convolutional Neural Network Architecture\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 5, 10) #in_channels, out_chanels, kernel_size\n","        self.pool = nn.MaxPool2d(2, 2) #kernel_size, stride\n","        self.conv2 = nn.Conv2d(5, 10, 5) #in_channels, out_chanels, kernel_size\n","\n","        # Calculate fully connected layer input\n","        self.a = int(((((224-10+1)/2)-5+1)/2))\n","\n","        self.fc1 = nn.Linear(10*self.a*self.a, 32)\n","        self.fc2 = nn.Linear(32, 2)\n","\n","        self.name = 'CNN'\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 10*self.a*self.a)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","    print('Convolutional Neural Network Architecture Done')\n","\n","\n","\n","\n","'''\n","# Reference from Lab2 and Tut3b\n","use_cuda = True\n","\n","def get_accuracy(model, data_loader):\n","    correct = 0\n","    total = 0\n","\n","    for imgs, labels in data_loader:\n","\n","        #############################################\n","        #To Enable GPU Usage\n","        if use_cuda and torch.cuda.is_available():\n","          imgs = imgs.cuda()\n","          labels = labels.cuda()\n","        #############################################\n","\n","        output = model(imgs)\n","\n","        #select index with maximum prediction score\n","        pred = output.max(1, keepdim=True)[1]\n","        correct += pred.eq(labels.view_as(pred)).sum().item()\n","        total += imgs.shape[0]\n","    return correct / total\n","'''\n","\n","\n","def CNN_train(model, train_data, valid_data, batch_size=1, learning_rate=0.05, num_epochs=1):\n","\n","    # Fixed PyTorch random seed for reproducible result\n","    torch.manual_seed(100)\n","\n","    # Obtain the PyTorch data loader objects to load batches of the datasets\n","    train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size,\n","                                               shuffle=True)\n","    val_loader = torch.utils.data.DataLoader(valid_data,batch_size=batch_size,\n","                                              shuffle=True)\n","\n","    # Define the Loss function and optimizer\n","    # The loss function will be Binary Cross Entropy (BCE)\n","    # so use the BCEWithLogitsLoss\n","    # Optimizer will be SGD with Momentum.\n","\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","\n","    iters, losses, train_acc, val_acc = [], [], [], []\n","    # Get a batch of training data\n","\n","    # Train the network\n","    # Loop over the data iterator and sample a new batch of training data\n","    # Get the output from the network, and optimize our loss function.\n","    itr_num = 0  # num of iterations\n","    for epoch in range(num_epochs):  # loop over the dataset multiple times\n","      try:\n","        i=0\n","        for imgs, labels in iter(train_loader):\n","            try:\n","                #############################################\n","                # To Enable GPU Usage\n","\n","                if use_cuda and torch.cuda.is_available():\n","                    imgs = imgs.cuda()\n","                    labels = labels.cuda()\n","                    print(\"using GPU\")\n","                #############################################\n","\n","                # Forward pass, backward pass, and optimize\n","                outputs = model(imgs)               # forward pass\n","                loss = criterion(outputs, labels)   # compute the total loss\n","                loss.backward()                     # backward pass (compute parameter updates)\n","                optimizer.step()                    # make the updates for each parameter\n","                optimizer.zero_grad()               # a clean up step for PyTorch\n","                print(i)\n","                i+=1\n","            except UnidentifiedImageError as e:\n","                print(f\"Error loading image: {e}\")\n","                continue  # Skip this batch and move to the next\n","\n","\n","        # save the current training information\n","        iters.append(epoch)\n","        losses.append(float(loss)/batch_size) # compute *average* loss\n","        # compute train accuracy\n","        train_acc.append(get_accuracy(model, train_loader))\n","        # compute validation accuracy\n","        val_acc.append(get_accuracy(model, val_loader))\n","\n","        print((\"Epoch {}: Train accuracy: {} |\"+\n","               \"Validation accuracy: {}\").format(epoch+1, train_acc[epoch],\n","                   val_acc[epoch],))\n","\n","        # Save the current model (checkpoint) to a file\n","        model_path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(\n","                              model.name, batch_size, learning_rate, epoch)\n","        torch.save(model.state_dict(), model_path)\n","\n","      except UnidentifiedImageError as e:\n","          print(f\"Error loading image: {e}\")\n","          continue  # Skip this batch and move to the next\n","\n","    print('Finished Training')\n","\n","\n","    # plotting\n","    plt.title(\"Training Curve\")\n","    plt.plot(iters, losses, label=\"Train\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    plt.title(\"Training Curve\")\n","    plt.plot(iters, train_acc, label=\"Training\")\n","    plt.plot(iters, val_acc, label=\"Validation\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Validation Accuracy\")\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n","    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zCgIZKK5UPpN","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1712440326846,"user_tz":240,"elapsed":540,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"}},"outputId":"cb385a8b-ce47-4dee-f768-df5f224e373c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntrain_data = datasets.ImageFolder(root=train_path, transform=data_transform)\\nvalid_data = datasets.ImageFolder(root=valid_path, transform=data_transform)\\ntest_data = datasets.ImageFolder(root=test_path, transform=data_transform)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}],"source":["'''\n","train_data = datasets.ImageFolder(root=train_path, transform=data_transform)\n","valid_data = datasets.ImageFolder(root=valid_path, transform=data_transform)\n","test_data = datasets.ImageFolder(root=test_path, transform=data_transform)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12477,"status":"ok","timestamp":1712455527358,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"FX6vMaDk4t6A","outputId":"ff035baa-3cfe-4827-9537-a6b7bc566e36"},"outputs":[{"output_type":"stream","name":"stdout","text":["CNN\n","CNN(\n","  (conv1): Conv2d(3, 5, kernel_size=(10, 10), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(5, 10, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=26010, out_features=32, bias=True)\n","  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",")\n"]}],"source":["print(\"CNN\")\n","model = CNN()\n","if use_cuda and torch.cuda.is_available():\n","  model.cuda()\n","print(model)\n","data = datasets.ImageFolder(root=train_path, transform=data_transform)\n","data2 = datasets.ImageFolder(root=valid_path, transform=data_transform)\n","data3 = datasets.ImageFolder(root=test_path, transform=data_transform)\n","final_data = torch.utils.data.ConcatDataset([data,data2,data3])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":266,"status":"ok","timestamp":1712457188532,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"0onoc7o7BP5s","outputId":"4b326ddd-f77f-4615-b4af-2af759454a15"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["9220"]},"metadata":{},"execution_count":94}],"source":["len(data3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1712457190750,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"w9DwioXT-z7A","outputId":"ae9fd7c2-b19e-41d2-fc08-f9d5d42bc7a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["5847\n","['0', '1']\n"]}],"source":["from torch.utils.data import Subset\n","from sklearn.model_selection import train_test_split\n","\n","# Define the subset of the data with the first 10,000 samples\n","\n","print(len(data))\n","print(data3.classes)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WL_IAj499mMn","executionInfo":{"status":"error","timestamp":1712457375651,"user_tz":240,"elapsed":3211,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"}},"colab":{"base_uri":"https://localhost:8080/","height":356},"outputId":"81c0ca44-1452-4b32-d6ed-e76e33addccc"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-102-ee4fe5ff80e1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Split the dataset into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Further split the training set into training and validation sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m     return list(\n\u001b[0m\u001b[1;32m   2586\u001b[0m         chain.from_iterable(\n\u001b[1;32m   2587\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2585\u001b[0m     return list(\n\u001b[1;32m   2586\u001b[0m         chain.from_iterable(\n\u001b[0;32m-> 2587\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m         )\n\u001b[1;32m   2589\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_list_indexing\u001b[0;34m(X, key, key_dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# key is a integer array-like of key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# key is a integer array-like of key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 )\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Split the dataset into training and testing sets\n","train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n","\n","# Further split the training set into training and validation sets\n","train_set, val_set = train_test_split(train_set, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"elapsed":3,"status":"error","timestamp":1712457573666,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"fKx2uzmEl8HY","outputId":"d5747935-04d4-4065-a94d-84ed20a1c04c"},"outputs":[{"output_type":"stream","name":"stdout","text":["CNN\n","CNN\n","Failed to move the model to GPU: CUDA error: device-side assert triggered\n","CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n","For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n","Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","\n","CNN(\n","  (conv1): Conv2d(3, 5, kernel_size=(10, 10), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(5, 10, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=26010, out_features=32, bias=True)\n","  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",")\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-106-aa02f35d47bd>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Check model structure (debugging output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mCNN_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-99-8152178a8182>\u001b[0m in \u001b[0;36mCNN_train\u001b[0;34m(model, train_data, valid_data, batch_size, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# Fixed PyTorch random seed for reproducible result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Obtain the PyTorch data loader objects to load batches of the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mdynamo_config_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/external_utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["use_cuda=True\n","print(\"CNN\")\n","model2 = CNN()\n","\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # For debugging CUDA errors\n","\n","print(\"CNN\")\n","model = CNN()\n","\n","# Check if CUDA is available and then move the model to GPU\n","use_cuda = True\n","if use_cuda and torch.cuda.is_available():\n","    try:\n","        model.cuda()\n","        print(\"Using GPU\")\n","    except RuntimeError as e:\n","        print(\"Failed to move the model to GPU:\", e)\n","        exit(1)\n","\n","# Check model structure (debugging output)\n","print(model)\n","CNN_train(model, data,data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18P2ClWpVVR3"},"outputs":[],"source":["# prompt: split the image dataset to train test and validation\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3760,"status":"ok","timestamp":1712450849552,"user":{"displayName":"Xinyue Li","userId":"04295590305038650711"},"user_tz":240},"id":"O3ODekCxVa9v","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3c068673-6af2-42b7-b914-fd367d1cc901"},"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","Epoch 1: Train accuracy: 100.0 |Validation accuracy: 100.0\n","Finished Training\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBhElEQVR4nO3dd3gVZf7+8fskpFdA0iAQpDdBASGIFIkEkM5KWZQigq6isoCFXRBBiiAiVVnXhQiiIEqzAGJoioiAgFGDAoYmCUhJQighnMzvD345Xw8JkEPOSRner+uay5xn2meeZDn3zjwzYzEMwxAAAIBJuRV1AQAAAK5E2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AHgMgMGDFBUVNQtrfvKK6/IYrE4tyAAtyXCDnAbslgs+Zo2bdpU1KUWqU2bNql79+4KCwuTp6enQkJC1KlTJy1fvryoSwPgAAvvxgJuP++//77d54ULF2r9+vVatGiRXfuDDz6o0NDQW95PVlaWsrOz5eXl5fC6V65c0ZUrV+Tt7X3L+y+IsWPHavz48apWrZr69OmjSpUq6fTp0/riiy+0adMmLV68WH//+9+LpDYAjiHsANDQoUM1d+5c3eyfgwsXLsjX17eQqio6H3/8sR5++GH97W9/0wcffCAPDw+7+evWrVNWVpY6duxY4H3dLn0KFCUuYwHIU6tWrVS3bl3t2rVLLVq0kK+vr/71r39JklatWqWHHnpIERER8vLyUpUqVfTqq6/KarXabePaMTuHDh2SxWLRtGnT9M4776hKlSry8vJS48aNtWPHDrt18xqzY7FYNHToUK1cuVJ169aVl5eX6tSpo7Vr1+aqf9OmTWrUqJG8vb1VpUoV/ec//8n3OKAxY8aoTJkymj9/fq6gI0mxsbG2oBMXFyeLxaJDhw7l2v+1lwKv16cdO3bUnXfemWct0dHRatSokV3b+++/r4YNG8rHx0dlypRR7969dfTo0ZseF3C7KlXUBQAovk6fPq327durd+/eeuSRR2yXtOLi4uTv76/hw4fL399fGzZs0Msvv6z09HS9/vrrN93uBx98oHPnzumJJ56QxWLR1KlT1b17d/3+++95hou/+uabb7R8+XI99dRTCggI0KxZs9SjRw8dOXJEZcuWlSTt3r1b7dq1U3h4uMaNGyer1arx48erXLlyN61t//792rdvnx577DEFBATko5cck1efNmzYUP369dOOHTvUuHFj27KHDx/Wd999Z9enEydO1JgxY9SzZ089/vjj+vPPPzV79my1aNFCu3fvVnBwsNNrBko8A8Bt7+mnnzau/eegZcuWhiRj3rx5uZa/cOFCrrYnnnjC8PX1NS5dumRr69+/v1GpUiXb56SkJEOSUbZsWePMmTO29lWrVhmSjE8//dTWNnbs2Fw1STI8PT2NAwcO2Nr27t1rSDJmz55ta+vUqZPh6+tr/PHHH7a2/fv3G6VKlcq1zWvl1PLmm2/ecLkcCxYsMCQZSUlJdu0bN240JBkbN260tV2vT9PS0gwvLy9jxIgRdu1Tp041LBaLcfjwYcMwDOPQoUOGu7u7MXHiRLvlEhISjFKlSuVqB3AVl7EAXJeXl5cGDhyYq93Hx8f287lz53Tq1Cndf//9unDhgvbt23fT7fbq1UulS5e2fb7//vslSb///vtN142JiVGVKlVsn++66y4FBgba1rVarfrqq6/UtWtXRURE2JarWrWq2rdvf9Ptp6enS5JLzupIefdpYGCg2rdvr48++shu3NTSpUvVtGlTVaxYUZK0fPlyZWdnq2fPnjp16pRtCgsLU7Vq1bRx40aX1AyUdFzGAnBd5cuXl6enZ672n3/+WaNHj9aGDRts4SBHWlraTbeb8+WdIyf4nD171uF1c9bPWffkyZO6ePGiqlatmmu5vNquFRgYKOlqiHOF6/Vpr169tHLlSm3btk3NmjXTwYMHtWvXLs2YMcO2zP79+2UYhqpVq5bntm92CRC4XRF2AFzXX8/g5EhNTVXLli0VGBio8ePHq0qVKvL29tYPP/ygF198UdnZ2Tfdrru7e57tRj5uDi3IuvlRs2ZNSVJCQkK+lr/egOdrB2vnyKtPJalTp07y9fXVRx99pGbNmumjjz6Sm5ubHn74Ydsy2dnZslgsWrNmTZ794O/vn6+agdsNYQeAQzZt2qTTp09r+fLlatGiha09KSmpCKv6PyEhIfL29taBAwdyzcur7VrVq1dXjRo1tGrVKs2cOfOmASLnrFRqaqpd++HDh/NftCQ/Pz917NhRy5Yt0/Tp07V06VLdf//9dpfiqlSpIsMwVLlyZVWvXt2h7QO3M8bsAHBIzhmFv55JuXz5st56662iKsmOu7u7YmJitHLlSh0/ftzWfuDAAa1ZsyZf2xg3bpxOnz6txx9/XFeuXMk1/8svv9Rnn30mSbbxQ1u2bLHNt1qteueddxyuvVevXjp+/Ljeffdd7d27V7169bKb3717d7m7u2vcuHG5zmQZhqHTp087vE/gdsCZHQAOadasmUqXLq3+/fvr2WeflcVi0aJFi5x2GckZXnnlFX355Ze677779I9//ENWq1Vz5sxR3bp1tWfPnpuu36tXLyUkJGjixInavXu33ROU165dq/j4eH3wwQeSpDp16qhp06YaNWqUzpw5ozJlymjJkiV5hqSb6dChgwICAjRy5Ei5u7urR48edvOrVKmiCRMmaNSoUTp06JC6du2qgIAAJSUlacWKFRoyZIhGjhzp8H4BsyPsAHBI2bJl9dlnn2nEiBEaPXq0SpcurUceeURt2rRRbGxsUZcnSWrYsKHWrFmjkSNHasyYMYqMjNT48eOVmJiYr7vFJGnChAl64IEHNGvWLL399ts6c+aMSpcuraZNm2rVqlXq3LmzbdnFixfriSee0Guvvabg4GANGjRIrVu31oMPPuhQ3d7e3urcubMWL16smJgYhYSE5FrmpZdeUvXq1fXmm29q3LhxkqTIyEi1bdvWriYA/4fXRQC4bXTt2lU///yz9u/fX9SlAChEjNkBYEoXL160+7x//3598cUXatWqVdEUBKDIcGYHgCmFh4drwIABuvPOO3X48GG9/fbbyszM1O7du6/7nBoA5sSYHQCm1K5dO3344YdKSUmRl5eXoqOjNWnSJIIOcBvizA4AADA1xuwAAABTI+wAAABTY8yOrr5v5vjx4woICLjue24AAEDxYhiGzp07p4iICLm5Xf/8DWFH0vHjxxUZGVnUZQAAgFtw9OhRVahQ4brzCTuSAgICJF3trMDAwCKuBgAA5Ed6eroiIyNt3+PXQ9iRbJeuAgMDCTsAAJQwNxuCwgBlAABgaoQdAABgaoQdAABgaozZAQCYitVqVVZWVlGXASfw8PCQu7t7gbdD2AEAmIJhGEpJSVFqampRlwInCg4OVlhYWIGeg0fYAQCYQk7QCQkJka+vLw+JLeEMw9CFCxd08uRJSVJ4ePgtb4uwAwAo8axWqy3olC1btqjLgZP4+PhIkk6ePKmQkJBbvqTFAGUAQImXM0bH19e3iCuBs+X8TgsyDouwAwAwDS5dmY8zfqeEHQAAYGqEHQAATCQqKkozZszI9/KbNm2SxWIx9V1shB0AAIqAxWK54fTKK6/c0nZ37NihIUOG5Hv5Zs2aKTk5WUFBQbe0v5KAu7EAACgCycnJtp+XLl2ql19+Wb/++qutzd/f3/azYRiyWq0qVermX9vlypVzqA5PT0+FhYU5tE5Jw5kdAACKQFhYmG0KCgqSxWKxfd63b58CAgK0Zs0aNWzYUF5eXvrmm2908OBBdenSRaGhofL391fjxo311Vdf2W332stYFotF7777rrp16yZfX19Vq1ZNq1evts2/9jJWXFycgoODtW7dOtWqVUv+/v5q166dXTi7cuWKnn32WQUHB6ts2bJ68cUX1b9/f3Xt2tWVXXbLCDsAANMxDEMXLl8pkskwDKcdx0svvaTXXntNiYmJuuuuu5SRkaEOHTooPj5eu3fvVrt27dSpUycdOXLkhtsZN26cevbsqR9//FEdOnRQ3759debMmesuf+HCBU2bNk2LFi3Sli1bdOTIEY0cOdI2f8qUKVq8eLEWLFigrVu3Kj09XStXrnTWYTsdl7EAAKZzMcuq2i+vK5J9/zI+Vr6ezvl6HT9+vB588EHb5zJlyqh+/fq2z6+++qpWrFih1atXa+jQodfdzoABA9SnTx9J0qRJkzRr1ix9//33ateuXZ7LZ2Vlad68eapSpYokaejQoRo/frxt/uzZszVq1Ch169ZNkjRnzhx98cUXt36gLsaZHQAAiqlGjRrZfc7IyNDIkSNVq1YtBQcHy9/fX4mJiTc9s3PXXXfZfvbz81NgYKDtNQx58fX1tQUd6eqrGnKWT0tL04kTJ3Tvvffa5ru7u6thw4YOHVth4swOAMB0fDzc9cv42CLbt7P4+fnZfR45cqTWr1+vadOmqWrVqvLx8dHf/vY3Xb58+Ybb8fDwsPtssViUnZ3t0PLOvDxX2Ag7AADTsVgsTruUVJxs3bpVAwYMsF0+ysjI0KFDhwq1hqCgIIWGhmrHjh1q0aKFpKvvJvvhhx/UoEGDQq0lv8z3lwAAgElVq1ZNy5cvV6dOnWSxWDRmzJgbnqFxlWeeeUaTJ09W1apVVbNmTc2ePVtnz54ttq/rYMwOAAAlxPTp01W6dGk1a9ZMnTp1UmxsrO65555Cr+PFF19Unz591K9fP0VHR8vf31+xsbHy9vYu9Fryw2KU5ItwTpKenq6goCClpaUpMDCwqMsBADjo0qVLSkpKUuXKlYvtF66ZZWdnq1atWurZs6deffVVp277Rr/b/H5/cxkLAAA45PDhw/ryyy/VsmVLZWZmas6cOUpKStLf//73oi4tT1zGAgAADnFzc1NcXJwaN26s++67TwkJCfrqq69Uq1atoi4tT5zZAQAADomMjNTWrVuLuox848wOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAlVKtWrTRs2DDb56ioKM2YMeOG61gsFq1cubLA+3bWdgoDYQcAgCLQqVMntWvXLs95X3/9tSwWi3788UeHtrljxw4NGTLEGeXZvPLKK3m+zTw5OVnt27d36r5chbADAEARGDRokNavX69jx47lmrdgwQI1atRId911l0PbLFeunHx9fZ1V4g2FhYXJy8urUPZVUIQdAACKQMeOHVWuXDnFxcXZtWdkZGjZsmXq2rWr+vTpo/Lly8vX11f16tXThx9+eMNtXnsZa//+/WrRooW8vb1Vu3ZtrV+/Ptc6L774oqpXry5fX1/deeedGjNmjLKysiRJcXFxGjdunPbu3SuLxSKLxWKr99rLWAkJCXrggQfk4+OjsmXLasiQIcrIyLDNHzBggLp27app06YpPDxcZcuW1dNPP23blyvxuggAgPkYhpR1oWj27eErWSw3XaxUqVLq16+f4uLi9O9//1uW/7/OsmXLZLVa9cgjj2jZsmV68cUXFRgYqM8//1yPPvqoqlSponvvvfem28/Ozlb37t0VGhqq7du3Ky0tzW58T46AgADFxcUpIiJCCQkJGjx4sAICAvTCCy+oV69e+umnn7R27Vp99dVXkqSgoKBc2zh//rxiY2MVHR2tHTt26OTJk3r88cc1dOhQuzC3ceNGhYeHa+PGjTpw4IB69eqlBg0aaPDgwTc9noIg7AAAzCfrgjQpomj2/a/jkqdfvhZ97LHH9Prrr2vz5s1q1aqVpKuXsHr06KFKlSpp5MiRtmWfeeYZrVu3Th999FG+ws5XX32lffv2ad26dYqIuNoXkyZNyjXOZvTo0bafo6KiNHLkSC1ZskQvvPCCfHx85O/vr1KlSiksLOy6+/rggw906dIlLVy4UH5+V499zpw56tSpk6ZMmaLQ0FBJUunSpTVnzhy5u7urZs2aeuihhxQfH+/ysMNlLAAAikjNmjXVrFkzzZ8/X5J04MABff311xo0aJCsVqteffVV1atXT2XKlJG/v7/WrVunI0eO5GvbiYmJioyMtAUdSYqOjs613NKlS3XfffcpLCxM/v7+Gj16dL738dd91a9f3xZ0JOm+++5Tdna2fv31V1tbnTp15O7ubvscHh6ukydPOrSvW8GZHQCA+Xj4Xj3DUlT7dsCgQYP0zDPPaO7cuVqwYIGqVKmili1basqUKZo5c6ZmzJihevXqyc/PT8OGDdPly5edVuq2bdvUt29fjRs3TrGxsQoKCtKSJUv0xhtvOG0ff+Xh4WH32WKxKDs72yX7+ivCDgDAfCyWfF9KKmo9e/bUc889pw8++EALFy7UP/7xD1ksFm3dulVdunTRI488IunqGJzffvtNtWvXztd2a9WqpaNHjyo5OVnh4eGSpO+++85umW+//VaVKlXSv//9b1vb4cOH7Zbx9PSU1Wq96b7i4uJ0/vx529mdrVu3ys3NTTVq1MhXva7EZSwAAIqQv7+/evXqpVGjRik5OVkDBgyQJFWrVk3r16/Xt99+q8TERD3xxBM6ceJEvrcbExOj6tWrq3///tq7d6++/vpru1CTs48jR45oyZIlOnjwoGbNmqUVK1bYLRMVFaWkpCTt2bNHp06dUmZmZq599e3bV97e3urfv79++uknbdy4Uc8884weffRR23idokTYAQCgiA0aNEhnz55VbGysbYzN6NGjdc899yg2NlatWrVSWFiYunbtmu9turm5acWKFbp48aLuvfdePf7445o4caLdMp07d9Y///lPDR06VA0aNNC3336rMWPG2C3To0cPtWvXTq1bt1a5cuXyvP3d19dX69at05kzZ9S4cWP97W9/U5s2bTRnzhzHO8MFLIZhGEVdRFFLT09XUFCQ0tLSFBgYWNTlAAAcdOnSJSUlJaly5cry9vYu6nLgRDf63eb3+7tIz+xs2bJFnTp1UkRERJ7v2DAMQy+//LLCw8Pl4+OjmJgY7d+/P89tZWZmqkGDBrJYLNqzZ4/riwcAACVCkYad8+fPq379+po7d26e86dOnapZs2Zp3rx52r59u/z8/BQbG6tLly7lWvaFF16wu70OAABAKuK7sdq3b3/dl4gZhqEZM2Zo9OjR6tKliyRp4cKFCg0N1cqVK9W7d2/bsmvWrNGXX36pTz75RGvWrCmU2gEAQMlQbAcoJyUlKSUlRTExMba2oKAgNWnSRNu2bbO1nThxQoMHD9aiRYsK7eVnAACg5Ci2z9lJSUmRpFy3rIWGhtrmGYahAQMG6Mknn1SjRo106NChfG07MzPT7ta59PR05xQNAChS3HNjPs74nRbbMzv5MXv2bJ07d06jRo1yaL3JkycrKCjINkVGRrqoQgBAYch5Mu+FC0X08k+4TM7v9NqnLzui2J7ZyXnh2IkTJ2xPfsz53KBBA0nShg0btG3bNnl5edmt26hRI/Xt21fvvfdentseNWqUhg8fbvucnp5O4AGAEszd3V3BwcG29yz5+vra3iKOkskwDF24cEEnT55UcHCw3Tu1HFVsw07lypUVFham+Ph4W7hJT0/X9u3b9Y9//EOSNGvWLE2YMMG2zvHjxxUbG6ulS5eqSZMm1922l5dXroAEACjZcv5PcmG8WBKFJzg4+IZvXM+PIg07GRkZOnDggO1zzuOoy5Qpo4oVK2rYsGGaMGGCqlWrpsqVK2vMmDGKiIiwPUGyYsWKdtvz9/eXJFWpUkUVKlQotOMAABQ9i8Wi8PBwhYSEKCsrq6jLgRN4eHgU6IxOjiINOzt37lTr1q1tn3MuLfXv319xcXF64YUXdP78eQ0ZMkSpqalq3ry51q5dy9MxAQDX5e7u7pQvSJgHr4sQr4sAAKAkKhGviwAAAHA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADC1Ig07W7ZsUadOnRQRESGLxaKVK1fazTcMQy+//LLCw8Pl4+OjmJgY7d+/3zb/0KFDGjRokCpXriwfHx9VqVJFY8eO1eXLlwv5SAAAQHFVpGHn/Pnzql+/vubOnZvn/KlTp2rWrFmaN2+etm/fLj8/P8XGxurSpUuSpH379ik7O1v/+c9/9PPPP+vNN9/UvHnz9K9//aswDwMAABRjFsMwjKIuQpIsFotWrFihrl27Srp6ViciIkIjRozQyJEjJUlpaWkKDQ1VXFycevfuned2Xn/9db399tv6/fff873v9PR0BQUFKS0tTYGBgQU+FgAA4Hr5/f4utmN2kpKSlJKSopiYGFtbUFCQmjRpom3btl13vbS0NJUpU6YwSgQAACVAqaIu4HpSUlIkSaGhoXbtoaGhtnnXOnDggGbPnq1p06bdcNuZmZnKzMy0fU5PTy9gtQAAoLhy+MyOI5eHCtMff/yhdu3a6eGHH9bgwYNvuOzkyZMVFBRkmyIjIwupSgAAUNgcDjtVq1ZV69at9f7779sGCrtCWFiYJOnEiRN27SdOnLDNy3H8+HG1bt1azZo10zvvvHPTbY8aNUppaWm26ejRo84rHAAAFCsOh50ffvhBd911l4YPH66wsDA98cQT+v77751eWOXKlRUWFqb4+HhbW3p6urZv367o6Ghb2x9//KFWrVqpYcOGWrBggdzcbn5IXl5eCgwMtJsAAIA5ORx2GjRooJkzZ+r48eOaP3++kpOT1bx5c9WtW1fTp0/Xn3/+me9tZWRkaM+ePdqzZ4+kq4OS9+zZoyNHjshisWjYsGGaMGGCVq9erYSEBPXr108RERG2O7Zygk7FihU1bdo0/fnnn0pJSbnumB4AAHD7KfCt55mZmXrrrbc0atQoXb58WZ6enurZs6emTJmi8PDwG667adMmtW7dOld7//79FRcXJ8MwNHbsWL3zzjtKTU1V8+bN9dZbb6l69eqSpLi4OA0cODDPbTtyWNx6DgBAyZPf7+9bDjs7d+7U/PnztWTJEvn5+al///4aNGiQjh07pnHjxik9Pd0ll7dcgbADAEDJk9/vb4dvPZ8+fboWLFigX3/9VR06dNDChQvVoUMH21iZypUrKy4uTlFRUbdcPAAAgLM4HHbefvttPfbYYxowYMB1L1OFhITof//7X4GLAwAAKKhi87qIosRlLAAASh6XvS5iwYIFWrZsWa72ZcuW6b333nN0cwAAAC7lcNiZPHmy7rjjjlztISEhmjRpklOKAgAAcBaHw86RI0dUuXLlXO2VKlXSkSNHnFIUAACAszgcdkJCQvTjjz/mat+7d6/Kli3rlKIAAACcxeGw06dPHz377LPauHGjrFarrFarNmzYoOeee069e/d2RY0AAAC3zOFbz1999VUdOnRIbdq0UalSV1fPzs5Wv379GLMDAACKnVu+9fy3337T3r175ePjo3r16qlSpUrOrq3QcOs5AAAlj8ueoJyjevXqtndUAQAAFFe3FHaOHTum1atX68iRI7p8+bLdvOnTpzulMAAAAGdwOOzEx8erc+fOuvPOO7Vv3z7VrVtXhw4dkmEYuueee1xRIwAAwC1z+G6sUaNGaeTIkUpISJC3t7c++eQTHT16VC1bttTDDz/sihoBAABumcNhJzExUf369ZMklSpVShcvXpS/v7/Gjx+vKVOmOL1AAACAgnA47Pj5+dnG6YSHh+vgwYO2eadOnXJeZQAAAE7g8Jidpk2b6ptvvlGtWrXUoUMHjRgxQgkJCVq+fLmaNm3qihoBAABumcNhZ/r06crIyJAkjRs3ThkZGVq6dKmqVavGnVgAAKDYcSjsWK1WHTt2THfddZekq5e05s2b55LCAAAAnMGhMTvu7u5q27atzp4966p6AAAAnMrhAcp169bV77//7opaAAAAnM7hsDNhwgSNHDlSn332mZKTk5Wenm43AQAAFCcOvwjUze3/8pHFYrH9bBiGLBaLrFar86orJLwIFACAksdlLwLduHFjgQoDAAAoTA6HnZYtW7qiDgAAAJdwOOxs2bLlhvNbtGhxy8UAAAA4m8Nhp1WrVrna/jp2pySO2QEAAObl8N1YZ8+etZtOnjyptWvXqnHjxvryyy9dUSMAAMAtc/jMTlBQUK62Bx98UJ6enho+fLh27drllMIAAACcweEzO9cTGhqqX3/91VmbAwAAcAqHz+z8+OOPdp8Nw1BycrJee+01NWjQwFl1AQAAOIXDYadBgwayWCy69lmETZs21fz5851WGAAAgDM4HHaSkpLsPru5ualcuXLy9vZ2WlEAAADO4nDYqVSpkivqAAAAcAmHByg/++yzmjVrVq72OXPmaNiwYc6oCQAAwGkcDjuffPKJ7rvvvlztzZo108cff+yUogAAAJzF4bBz+vTpPJ+1ExgYqFOnTjmlKAAAAGdxOOxUrVpVa9euzdW+Zs0a3XnnnU4pCgAAwFkcHqA8fPhwDR06VH/++aceeOABSVJ8fLzeeOMNzZgxw9n1AQAAFIjDYeexxx5TZmamJk6cqFdffVWSFBUVpbffflv9+vVzeoEAAAAFYTGufTqgA/7880/5+PjI39/fmTUVuvT0dAUFBSktLU2BgYFFXQ4AAMiH/H5/39JDBa9cuaJq1aqpXLlytvb9+/fLw8NDUVFRt1QwAACAKzg8QHnAgAH69ttvc7Vv375dAwYMcEZNAAAATuNw2Nm9e3eez9lp2rSp9uzZ44yaAAAAnMbhsGOxWHTu3Llc7WlpabJarU4pCgAAwFkcDjstWrTQ5MmT7YKN1WrV5MmT1bx5c6cWBwAAUFAOD1CeMmWKWrRooRo1auj++++XJH399ddKT0/Xhg0bnF4gAABAQTh8Zqd27dr68ccf1bNnT508eVLnzp1Tv379tG/fPtWtW9cVNQIAANyyAj1n569SU1P1/vvva+jQoc7YXKHiOTsAAJQ8+f3+dvjMzrXi4+P197//XeHh4Ro7dmxBNwcAAOBUtxR2jh49qvHjx6ty5cpq27atJGnFihVKSUlxanEAAAAFle+wk5WVpWXLlik2NlY1atTQnj179Prrr8vNzU2jR49Wu3bt5OHh4cpaAQAAHJbvu7HKly+vmjVr6pFHHtGSJUtUunRpSVKfPn1cVhwAAEBB5fvMzpUrV2SxWGSxWOTu7u7KmgAAAJwm32Hn+PHjGjJkiD788EOFhYWpR48eWrFihSwWiyvrAwAAKJB8hx1vb2/17dtXGzZsUEJCgmrVqqVnn31WV65c0cSJE7V+/XpeFwEAAIqdW7obq0qVKpowYYIOHz6szz//XJmZmerYsaNCQ0OdXR8AAECBFOg5O25ubmrfvr0+/vhjHTt2TP/6178cWn/Lli3q1KmTIiIiZLFYtHLlSrv5hmHo5ZdfVnh4uHx8fBQTE6P9+/fbLXPmzBn17dtXgYGBCg4O1qBBg5SRkVGQwwIAACZS4IcK5ihXrpyGDx/u0Drnz59X/fr1NXfu3DznT506VbNmzdK8efO0fft2+fn5KTY2VpcuXbIt07dvX/38889av369PvvsM23ZskVDhgwp0LEAAADzcNrrIgrKYrFoxYoV6tq1q6SrZ3UiIiI0YsQIjRw5UpKUlpam0NBQxcXFqXfv3kpMTFTt2rW1Y8cONWrUSJK0du1adejQQceOHVNERES+9s3rIgAAKHkK7XURrpKUlKSUlBTFxMTY2oKCgtSkSRNt27ZNkrRt2zYFBwfbgo4kxcTEyM3NTdu3b7/utjMzM5Wenm43AQAAcyq2YSfn1RPXDnoODQ21zUtJSVFISIjd/FKlSqlMmTI3fHXF5MmTFRQUZJsiIyOdXD0AACguim3YcaVRo0YpLS3NNh09erSoSwIAAC6S79dF5LBarYqLi1N8fLxOnjyp7Oxsu/kbNmxwSmFhYWGSpBMnTig8PNzWfuLECTVo0MC2zMmTJ+3Wu3Llis6cOWNbPy9eXl7y8vJySp0AAKB4c/jMznPPPafnnntOVqtVdevWVf369e0mZ6lcubLCwsIUHx9va0tPT9f27dsVHR0tSYqOjlZqaqp27dplW2bDhg3Kzs5WkyZNnFYLAAAouRw+s7NkyRJ99NFH6tChQ4F3npGRoQMHDtg+JyUlac+ePSpTpowqVqyoYcOGacKECapWrZoqV66sMWPGKCIiwnbHVq1atdSuXTsNHjxY8+bNU1ZWloYOHarevXvn+04sAABgbg6HHU9PT1WtWtUpO9+5c6dat25t+5zznJ7+/fsrLi5OL7zwgs6fP68hQ4YoNTVVzZs319q1a+Xt7W1bZ/HixRo6dKjatGkjNzc39ejRQ7NmzXJKfQAAoORz+Dk7b7zxhn7//XfNmTPHNC8B5Tk7AACUPPn9/nb4zM4333yjjRs3as2aNapTp448PDzs5i9fvtzxagEAAFzE4bATHBysbt26uaIWAAAAp3M47CxYsMAVdQAAALiEw2Enx59//qlff/1VklSjRg2VK1fOaUUBAAA4i8PP2Tl//rwee+wxhYeHq0WLFmrRooUiIiI0aNAgXbhwwRU1AgAA3DKHw87w4cO1efNmffrpp0pNTVVqaqpWrVqlzZs3a8SIEa6oEQAA4JY5fOv5HXfcoY8//litWrWya9+4caN69uypP//805n1FQpuPQcAoOTJ7/e3w2d2Lly4kOtN5JIUEhLCZSwAAFDsOBx2oqOjNXbsWF26dMnWdvHiRY0bN872zioAAIDiwuG7sWbOnKnY2FhVqFDB9uLPvXv3ytvbW+vWrXN6gQAAAAXh8Jgd6eqlrMWLF2vfvn2Srr6Qs2/fvvLx8XF6gYWBMTsAAJQ8LntdhCT5+vpq8ODBt1wcAABAYclX2Fm9erXat28vDw8PrV69+obLdu7c2SmFAQAAOEO+LmO5ubkpJSVFISEhcnO7/phmi8Uiq9Xq1AILA5exAAAoeZx6GSs7OzvPnwEAAIo7h289X7hwoTIzM3O1X758WQsXLnRKUQAAAM7i8N1Y7u7uSk5OVkhIiF376dOnFRISwmUsAABQKFz2BGXDMGSxWHK1Hzt2TEFBQY5uDgAAwKXyfev53XffLYvFIovFojZt2qhUqf9b1Wq1KikpSe3atXNJkQAAALcq32Gna9eukqQ9e/YoNjZW/v7+tnmenp6KiopSjx49nF4gAABAQeQ77IwdO1aSFBUVpV69esnb29tlRQEAADiLw09Q7t+/vyvqAAAAcAmHw47VatWbb76pjz76SEeOHNHly5ft5p85c8ZpxQEAABSUw3djjRs3TtOnT1evXr2Ulpam4cOHq3v37nJzc9Mrr7zighIBAABuncNhZ/Hixfrvf/+rESNGqFSpUurTp4/effddvfzyy/ruu+9cUSMAAMAtczjspKSkqF69epIkf39/paWlSZI6duyozz//3LnVAQAAFJDDYadChQpKTk6WJFWpUkVffvmlJGnHjh3y8vJybnUAAAAF5HDY6datm+Lj4yVJzzzzjMaMGaNq1aqpX79+euyxx5xeIAAAQEE4/G6sa23btk3btm1TtWrV1KlTJ2fVVah4NxYAACVPfr+/Hb71/FrR0dGKjo4u6GYAAABcIl9hZ/Xq1fneYOfOnW+5GAAAAGfLV9jJeS9WDovFomuvfuW8Cd1qtTqnMgAAACfI1wDl7Oxs2/Tll1+qQYMGWrNmjVJTU5Wamqo1a9bonnvu0dq1a11dLwAAgEMcHrMzbNgwzZs3T82bN7e1xcbGytfXV0OGDFFiYqJTCwQAACgIh289P3jwoIKDg3O1BwUF6dChQ04oCQAAwHkcDjuNGzfW8OHDdeLECVvbiRMn9Pzzz+vee+91anEAAAAF5XDYmT9/vpKTk1WxYkVVrVpVVatWVcWKFfXHH3/of//7nytqBAAAuGUOj9mpWrWqfvzxR61fv1779u2TJNWqVUsxMTG2O7IAAACKiwI/QdkMeIIyAAAlj1OfoDxr1iwNGTJE3t7emjVr1g2XffbZZx2rFAAAwIXydWancuXK2rlzp8qWLavKlStff2MWi37//XenFlgYOLMDAEDJ49QzO0lJSXn+DAAAUNw5fDcWAABASZKvMzvDhw/P9wanT59+y8UAAAA4W77Czu7du/O1MW49BwAAxU2+ws7GjRtdXQcAAIBLMGYHAACYmsNPUJaknTt36qOPPtKRI0d0+fJlu3nLly93SmEAAADO4PCZnSVLlqhZs2ZKTEzUihUrlJWVpZ9//lkbNmxQUFCQK2oEAAC4ZQ6HnUmTJunNN9/Up59+Kk9PT82cOVP79u1Tz549VbFiRVfUCAAAcMscDjsHDx7UQw89JEny9PTU+fPnZbFY9M9//lPvvPOO0wsEAAAoCIfDTunSpXXu3DlJUvny5fXTTz9JklJTU3XhwgXnVgcAAFBADg9QbtGihdavX6969erp4Ycf1nPPPacNGzZo/fr1atOmjStqBAAAuGX5Djs//fST6tatqzlz5ujSpUuSpH//+9/y8PDQt99+qx49emj06NEuKxQAAOBW5Out55Lk5uamxo0b6/HHH1fv3r0VEBDg6toKDW89BwCg5Mnv93e+x+xs3rxZderU0YgRIxQeHq7+/fvr66+/dkqxAAAArpLvsHP//fdr/vz5Sk5O1uzZs3Xo0CG1bNlS1atX15QpU5SSkuKSAs+dO6dhw4apUqVK8vHxUbNmzbRjxw7b/IyMDA0dOlQVKlSQj4+PateurXnz5rmkFgAAUPI4fDeWn5+fBg4cqM2bN+u3337Tww8/rLlz56pixYrq3Lmz0wt8/PHHtX79ei1atEgJCQlq27atYmJi9Mcff0i6+kb2tWvX6v3331diYqKGDRumoUOHavXq1U6vBQAAlDz5HrNzPefPn9fixYs1atQopaamymq1Oqs2Xbx4UQEBAVq1apXt2T6S1LBhQ7Vv314TJkxQ3bp11atXL40ZMybP+fnBmB0AAEoep4/ZudaWLVs0YMAAhYWF6fnnn1f37t21devWW91cnq5cuSKr1Spvb2+7dh8fH33zzTeSpGbNmmn16tX6448/ZBiGNm7cqN9++01t27a97nYzMzOVnp5uNwEAAHNyKOwcP35ckyZNUvXq1dWqVSsdOHBAs2bN0vHjx/Xf//5XTZs2dWpxAQEBio6O1quvvqrjx4/LarXq/fff17Zt25ScnCxJmj17tmrXrq0KFSrI09NT7dq109y5c9WiRYvrbnfy5MkKCgqyTZGRkU6tGwAAFB/5Djvt27dXpUqVNHv2bHXr1k2JiYn65ptvNHDgQPn5+bmswEWLFskwDJUvX15eXl6aNWuW+vTpIze3q6XPnj1b3333nVavXq1du3bpjTfe0NNPP62vvvrqutscNWqU0tLSbNPRo0ddVj8AACha+R6z07lzZw0aNEgdO3aUu7u7q+vK5fz580pPT1d4eLh69eqljIwMffzxxwoKCtKKFSvsxvQ8/vjjOnbsmNauXZuvbTNmBwCAkie/39/5foJyUd/d5OfnJz8/P509e1br1q3T1KlTlZWVpaysLNtZnhzu7u7Kzs4uokoBAEBx4vC7sQrbunXrZBiGatSooQMHDuj5559XzZo1NXDgQHl4eKhly5Z6/vnn5ePjo0qVKmnz5s1auHChpk+fXtSlAwCAYqDYh520tDSNGjVKx44dU5kyZdSjRw9NnDhRHh4ekqQlS5Zo1KhR6tu3r86cOaNKlSpp4sSJevLJJ4u4cgAAUBwU+Dk7ZsCYHQAASh6XP2cHAACgJCDsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyPsAAAAUyv2YefcuXMaNmyYKlWqJB8fHzVr1kw7duywWyYxMVGdO3dWUFCQ/Pz81LhxYx05cqSIKgYAAMVJsQ87jz/+uNavX69FixYpISFBbdu2VUxMjP744w9J0sGDB9W8eXPVrFlTmzZt0o8//qgxY8bI29u7iCsHAADFgcUwDKOoi7ieixcvKiAgQKtWrdJDDz1ka2/YsKHat2+vCRMmqHfv3vLw8NCiRYtueT/p6ekKCgpSWlqaAgMDnVE6AABwsfx+fxfrMztXrlyR1WrNdZbGx8dH33zzjbKzs/X555+revXqio2NVUhIiJo0aaKVK1fecLuZmZlKT0+3mwAAgDkV67ATEBCg6Ohovfrqqzp+/LisVqvef/99bdu2TcnJyTp58qQyMjL02muvqV27dvryyy/VrVs3de/eXZs3b77udidPnqygoCDbFBkZWYhHBQAAClOxvowlXR2T89hjj2nLli1yd3fXPffco+rVq2vXrl2Kj49X+fLl1adPH33wwQe2dTp37iw/Pz99+OGHeW4zMzNTmZmZts/p6emKjIzkMhYAACWIKS5jSVKVKlW0efNmZWRk6OjRo/r++++VlZWlO++8U3fccYdKlSql2rVr261Tq1atG96N5eXlpcDAQLsJAACYU7EPOzn8/PwUHh6us2fPat26derSpYs8PT3VuHFj/frrr3bL/vbbb6pUqVIRVQoAAIqTUkVdwM2sW7dOhmGoRo0aOnDggJ5//nnVrFlTAwcOlCQ9//zz6tWrl1q0aKHWrVtr7dq1+vTTT7Vp06aiLRwAABQLxf7MTlpamp5++mnVrFlT/fr1U/PmzbVu3Tp5eHhIkrp166Z58+Zp6tSpqlevnt5991198sknat68eRFXDgAAioNiP0C5MPCcHQAASh7TDFAGAAAoCMIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwtVJFXUBxYBiGJCk9Pb2IKwEAAPmV872d8z1+PYQdSefOnZMkRUZGFnElAADAUefOnVNQUNB151uMm8Wh20B2draOHz+ugIAAWSyWoi6nSKWnpysyMlJHjx5VYGBgUZdjWvRz4aGvCwf9XDjoZ3uGYejcuXOKiIiQm9v1R+ZwZkeSm5ubKlSoUNRlFCuBgYH8D6kQ0M+Fh74uHPRz4aCf/8+NzujkYIAyAAAwNcIOAAAwNcIO7Hh5eWns2LHy8vIq6lJMjX4uPPR14aCfCwf9fGsYoAwAAEyNMzsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDu3oTNnzqhv374KDAxUcHCwBg0apIyMjBuuc+nSJT399NMqW7as/P391aNHD504cSLPZU+fPq0KFSrIYrEoNTXVBUdQMriin/fu3as+ffooMjJSPj4+qlWrlmbOnOnqQylW5s6dq6ioKHl7e6tJkyb6/vvvb7j8smXLVLNmTXl7e6tevXr64osv7OYbhqGXX35Z4eHh8vHxUUxMjPbv3+/KQygRnNnPWVlZevHFF1WvXj35+fkpIiJC/fr10/Hjx119GCWCs/+m/+rJJ5+UxWLRjBkznFx1CWPgttOuXTujfv36xnfffWd8/fXXRtWqVY0+ffrccJ0nn3zSiIyMNOLj442dO3caTZs2NZo1a5bnsl26dDHat29vSDLOnj3rgiMoGVzRz//73/+MZ5991ti0aZNx8OBBY9GiRYaPj48xe/ZsVx9OsbBkyRLD09PTmD9/vvHzzz8bgwcPNoKDg40TJ07kufzWrVsNd3d3Y+rUqcYvv/xijB492vDw8DASEhJsy7z22mtGUFCQsXLlSmPv3r1G586djcqVKxsXL14srMMqdpzdz6mpqUZMTIyxdOlSY9++fca2bduMe++912jYsGFhHlax5Iq/6RzLly836tevb0RERBhvvvmmi4+keCPs3GZ++eUXQ5KxY8cOW9uaNWsMi8Vi/PHHH3muk5qaanh4eBjLli2ztSUmJhqSjG3bttkt+9ZbbxktW7Y04uPjb+uw4+p+/qunnnrKaN26tfOKL8buvfde4+mnn7Z9tlqtRkREhDF58uQ8l+/Zs6fx0EMP2bU1adLEeOKJJwzDMIzs7GwjLCzMeP31123zU1NTDS8vL+PDDz90wRGUDM7u57x8//33hiTj8OHDzim6hHJVXx87dswoX7688dNPPxmVKlW67cMOl7FuM9u2bVNwcLAaNWpka4uJiZGbm5u2b9+e5zq7du1SVlaWYmJibG01a9ZUxYoVtW3bNlvbL7/8ovHjx2vhwoU3fCHb7cCV/XyttLQ0lSlTxnnFF1OXL1/Wrl277PrHzc1NMTEx1+2fbdu22S0vSbGxsbblk5KSlJKSYrdMUFCQmjRpcsM+NzNX9HNe0tLSZLFYFBwc7JS6SyJX9XV2drYeffRRPf/886pTp45rii9hbu9vpNtQSkqKQkJC7NpKlSqlMmXKKCUl5brreHp65vpHKTQ01LZOZmam+vTpo9dff10VK1Z0Se0liav6+Vrffvutli5dqiFDhjil7uLs1KlTslqtCg0NtWu/Uf+kpKTccPmc/zqyTbNzRT9f69KlS3rxxRfVp0+f2/pllq7q6ylTpqhUqVJ69tlnnV90CUXYMYmXXnpJFovlhtO+fftctv9Ro0apVq1aeuSRR1y2j+KgqPv5r3766Sd16dJFY8eOVdu2bQtln0BBZWVlqWfPnjIMQ2+//XZRl2M6u3bt0syZMxUXFyeLxVLU5RQbpYq6ADjHiBEjNGDAgBsuc+eddyosLEwnT560a79y5YrOnDmjsLCwPNcLCwvT5cuXlZqaanfW4cSJE7Z1NmzYoISEBH388ceSrt7hIkl33HGH/v3vf2vcuHG3eGTFS1H3c45ffvlFbdq00ZAhQzR69OhbOpaS5o477pC7u3uuuwDz6p8cYWFhN1w+578nTpxQeHi43TINGjRwYvUlhyv6OUdO0Dl8+LA2bNhwW5/VkVzT119//bVOnjxpd4bdarVqxIgRmjFjhg4dOuTcgygpinrQEApXzsDZnTt32trWrVuXr4GzH3/8sa1t3759dgNnDxw4YCQkJNim+fPnG5KMb7/99rp3FZiZq/rZMAzjp59+MkJCQoznn3/edQdQTN17773G0KFDbZ+tVqtRvnz5Gw7m7Nixo11bdHR0rgHK06ZNs81PS0tjgLKT+9kwDOPy5ctG165djTp16hgnT550TeElkLP7+tSpU3b/FickJBgRERHGiy++aOzbt891B1LMEXZuQ+3atTPuvvtuY/v27cY333xjVKtWze6W6GPHjhk1atQwtm/fbmt78sknjYoVKxobNmwwdu7caURHRxvR0dHX3cfGjRtv67uxDMM1/ZyQkGCUK1fOeOSRR4zk5GTbdLt8eSxZssTw8vIy4uLijF9++cUYMmSIERwcbKSkpBiGYRiPPvqo8dJLL9mW37p1q1GqVClj2rRpRmJiojF27Ng8bz0PDg42Vq1aZfz4449Gly5duPXcyf18+fJlo3PnzkaFChWMPXv22P3tZmZmFskxFheu+Ju+FndjEXZuS6dPnzb69Olj+Pv7G4GBgcbAgQONc+fO2eYnJSUZkoyNGzfa2i5evGg89dRTRunSpQ1fX1+jW7duRnJy8nX3QdhxTT+PHTvWkJRrqlSpUiEeWdGaPXu2UbFiRcPT09O49957je+++842r2XLlkb//v3tlv/oo4+M6tWrG56enkadOnWMzz//3G5+dna2MWbMGCM0NNTw8vIy2rRpY/z666+FcSjFmjP7OedvPa/pr3//tytn/01fi7BjGBbD+P+DKwAAAEyIu7EAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYA3JaioqI0Y8aMoi4DQCEg7ABwuQEDBqhr166SpFatWmnYsGGFtu+4uDi7F6vm2LFjh4YMGVJodQAoOrz1HECJdPnyZXl6et7y+uXKlXNiNQCKM87sACg0AwYM0ObNmzVz5kxZLBZZLBYdOnRIkvTTTz+pffv28vf3V2hoqB599FGdOnXKtm6rVq00dOhQDRs2THfccYdiY2MlSdOnT1e9evXk5+enyMhIPfXUU8rIyJAkbdq0SQMHDlRaWpptf6+88oqk3Jexjhw5oi5dusjf31+BgYHq2bOnTpw4YZv/yiuvqEGDBlq0aJGioqIUFBSk3r1769y5c7ZlPv74Y9WrV08+Pj4qW7asYmJidP78eRf1JoD8IuwAKDQzZ85UdHS0Bg8erOTkZCUnJysyMlKpqal64IEHdPfdd2vnzp1au3atTpw4oZ49e9qt/95778nT01Nbt27VvHnzJElubm6aNWuWfv75Z7333nvasGGDXnjhBUlSs2bNNGPGDAUGBtr2N3LkyFx1ZWdnq0uXLjpz5ow2b96s9evX6/fff1evXr3sljt48KBWrlypzz77TJ999pk2b96s1157TZKUnJysPn366LHHHlNiYqI2bdqk7t27i9cPAkWPy1gACk1QUJA8PT3l6+ursLAwW/ucOXN09913a9KkSba2+fPnKzIyUr/99puqV68uSapWrZqmTp1qt82/jv+JiorShAkT9OSTT+qtt96Sp6engoKCZLFY7PZ3rfj4eCUkJCgpKUmRkZGSpIULF6pOnTrasWOHGjduLOlqKIqLi1NAQIAk6dFHH1V8fLwmTpyo5ORkXblyRd27d1elSpUkSfXq1StAbwFwFs7sAChye/fu1caNG+Xv72+batasKenq2ZQcDRs2zLXuV199pTZt2qh8+fIKCAjQo48+qtOnT+vChQv53n9iYqIiIyNtQUeSateureDgYCUmJtraoqKibEFHksLDw3Xy5ElJUv369dWmTRvVq1dPDz/8sP773//q7Nmz+e8EAC5D2AFQ5DIyMtSpUyft2bPHbtq/f79atGhhW87Pz89uvUOHDqljx46666679Mknn2jXrl2aO3eupKsDmJ3Nw8PD7rPFYlF2drYkyd3dXevXr9eaNWtUu3ZtzZ49WzVq1FBSUpLT6wDgGMIOgELl6ekpq9Vq13bPPffo559/VlRUlKpWrWo3XRtw/mrXrl3Kzs7WG2+8oaZNm6p69eo6fvz4Tfd3rVq1auno0aM6evSore2XX35Ramqqateune9js1gsuu+++zRu3Djt3r1bnp6eWrFiRb7XB+AahB0AhSoqKkrbt2/XoUOHdOrUKWVnZ+vpp5/WmTNn1KdPH+3YsUMHDx7UunXrNHDgwBsGlapVqyorK0uzZ8/W77//rkWLFtkGLv91fxkZGYqPj9epU6fyvLwVExOjevXqqW/fvvrhhx/0/fffq1+/fmrZsqUaNWqUr+Pavn27Jk2apJ07d+rIkSNavny5/vzzT9WqVcuxDgLgdIQdAIVq5MiRcnd3V+3atVWuXDkdOXJEERER2rp1q6xWq9q2bat69epp2LBhCg4Olpvb9f+Zql+/vqZPn64pU6aobt26Wrx4sSZPnmy3TLNmzfTkk0+qV69eKleuXK4BztLVMzKrVq1S6dKl1aJFC8XExOjOO+/U0qVL831cgYGB2rJlizp06KDq1atr9OjReuONN9S+ffv8dw4Al7AY3BcJAABMjDM7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1P4fLIopqLQFwZoAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Final Training Accuracy: 100.0\n","Final Validation Accuracy: 100.0\n"]}],"source":["#primary model、\n","use_cuda=False\n","model2 = CNN()\n","CNN_train(model2, train_set, val_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VfVWas-M4bIY"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}